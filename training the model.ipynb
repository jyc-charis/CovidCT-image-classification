{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_part.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqGk9-9t9R93",
        "outputId": "985da9e6-e2b2-44ff-fcbe-6e3aca831809"
      },
      "source": [
        "import torch \r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\r\n",
        "import torchvision\r\n",
        "from torchvision import datasets, transforms\r\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\r\n",
        "from torchvision.utils import save_image\r\n",
        "import torchvision.utils as vutils\r\n",
        "\r\n",
        "from torchsummary import summary\r\n",
        "\r\n",
        "import spacy\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import os\r\n",
        "import time\r\n",
        "import math\r\n",
        "from PIL import Image\r\n",
        "from PIL import ImageFile\r\n",
        "import skimage\r\n",
        "from skimage.io import imread, imsave\r\n",
        "import glob\r\n",
        "from IPython.display import display\r\n",
        "\r\n",
        "import torch.optim as optim\r\n",
        "from torch.optim.lr_scheduler import StepLR\r\n",
        "from datetime import datetime\r\n",
        "import random \r\n",
        "from torchvision.datasets import ImageFolder\r\n",
        "import re\r\n",
        "from torch.optim.lr_scheduler import StepLR\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "\r\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f0ef0552b88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEzy0wnrAN0R"
      },
      "source": [
        "workspace_dir = '.'\r\n",
        "!gdown --id '1E7sVpfnil2Oc6iWl_1iG-dHu2wf6m9K4' --output \"{workspace_dir}/image.zip\"\r\n",
        "!gdown --id '15T9x8yvQSdZveNqypH-4aYu_WJ2fsXes' --output \"{workspace_dir}/data.zip\"\r\n",
        "!gdown --id '11_CpQeWQZPH15nj6U9XtyXaYWlqRgspO' --output \"{workspace_dir}/Covid__g.pth\"\r\n",
        "!gdown --id '1c0pOdE4uEabPDh4xe3nkxR_ylJDqLeJZ' --output \"{workspace_dir}/NonCovid__g.pth\"\r\n",
        "!unzip -q \"{workspace_dir}/image.zip\" -d \"{workspace_dir}/\"\r\n",
        "!unzip -q \"{workspace_dir}/data.zip\" -d \"{workspace_dir}/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJzISkXbPRYT"
      },
      "source": [
        "# pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EwIb8QpPQz4"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "class ImgDataset(Dataset):\r\n",
        "    def __init__(self, fnames, transform):\r\n",
        "        self.transform = transform\r\n",
        "        self.fnames = fnames\r\n",
        "        self.num_samples = len(self.fnames)\r\n",
        "    def __len__(self):\r\n",
        "        return self.num_samples\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        fname = self.fnames[idx]\r\n",
        "        img = cv2.imread(fname, 0)\r\n",
        "        img = self.transform(img)\r\n",
        "        return img\r\n",
        "\r\n",
        "import glob\r\n",
        "import torchvision.transforms as transforms\r\n",
        "\r\n",
        "def get_dataset(root):\r\n",
        "    fnames = glob.glob(os.path.join(root, '*'))\r\n",
        "    # resize the image to (64, 64)\r\n",
        "    # linearly map [0, 1] to [-1, 1]\r\n",
        "    transform = transforms.Compose(\r\n",
        "         [transforms.ToPILImage(),\r\n",
        "         transforms.Resize((64, 64)),\r\n",
        "         transforms.CenterCrop(64),\r\n",
        "         transforms.ToTensor(),\r\n",
        "         transforms.Normalize(mean=[0.5], std=[0.5]) ] )\r\n",
        "    dataset = ImgDataset(fnames, transform)\r\n",
        "    return dataset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJT_cu0PPsOT"
      },
      "source": [
        "pip install timm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "megGcDVpPu79"
      },
      "source": [
        "import timm\r\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True)\r\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp2K768vQfke"
      },
      "source": [
        "# generate images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNZGL11rQioL"
      },
      "source": [
        "# Generator Code\r\n",
        "\r\n",
        "class Generator(nn.Module):\r\n",
        "    \"\"\"\r\n",
        "    input (N, in_dim)\r\n",
        "    output (N, 1, 64, 64)\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, in_dim, dim=64):\r\n",
        "        super(Generator, self).__init__()\r\n",
        "        def dconv_bn_relu(in_dim, out_dim):\r\n",
        "            return nn.Sequential(\r\n",
        "                nn.ConvTranspose2d(in_dim, out_dim, 5, 2,\r\n",
        "                                   padding=2, output_padding=1, bias=False),\r\n",
        "                nn.BatchNorm2d(out_dim),\r\n",
        "                nn.ReLU())\r\n",
        "        self.l1 = nn.Sequential(\r\n",
        "            nn.Linear(in_dim, dim * 8 * 4 * 4, bias=False),\r\n",
        "            nn.BatchNorm1d(dim * 8 * 4 * 4),\r\n",
        "            nn.ReLU())\r\n",
        "        self.l2_5 = nn.Sequential(\r\n",
        "            dconv_bn_relu(dim * 8, dim * 4),\r\n",
        "            dconv_bn_relu(dim * 4, dim * 2),\r\n",
        "            dconv_bn_relu(dim * 2, dim),\r\n",
        "            nn.ConvTranspose2d(dim, 1, 5, 2, padding=2, output_padding=1),\r\n",
        "            nn.Tanh())\r\n",
        "        self.apply(weights_init)\r\n",
        "    def forward(self, x):\r\n",
        "        y = self.l1(x)\r\n",
        "        y = y.view(y.size(0), -1, 4, 4)\r\n",
        "        y = self.l2_5(y)\r\n",
        "        return y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YulWQG8X8oms"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "def weights_init(m):\r\n",
        "    classname = m.__class__.__name__\r\n",
        "    if classname.find('Conv') != -1:\r\n",
        "        m.weight.data.normal_(0.0, 0.02)\r\n",
        "    elif classname.find('BatchNorm') != -1:\r\n",
        "        m.weight.data.normal_(1.0, 0.02)\r\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grbgj5fPRqTQ"
      },
      "source": [
        "## COVID part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3PNM5aDQ4Lo"
      },
      "source": [
        "# load pretrained model\r\n",
        "z_dim = 100\r\n",
        "G = Generator(z_dim)\r\n",
        "G.load_state_dict(torch.load('/content/Covid__g.pth')) \r\n",
        "G.eval()\r\n",
        "G.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJLvlX2TRXNy"
      },
      "source": [
        "# generate images and save the result\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "txtFile = open(\"/content/Data/data/COVID/trainCT_COVID.txt\",\"a+\")\r\n",
        "txtFile.writelines('\\n')\r\n",
        "for epoch in range(2000):\r\n",
        "  n_output = 1\r\n",
        "  z_sample = Variable(torch.randn(n_output, z_dim)).cuda()\r\n",
        "  imgs_sample = (G(z_sample).data + 1) / 2.0\r\n",
        "  save_dir = '/content/Images/image/CT_COVID'\r\n",
        "  filename = os.path.join(save_dir, f'Covid_{epoch+1:03d}.jpg')\r\n",
        "  txtFile.write(f'Covid_{epoch+1:03d}.jpg\\n')\r\n",
        "  torchvision.utils.save_image(imgs_sample, filename, nrow=1)\r\n",
        "txtFile.close()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU7rJ3qTRuqN"
      },
      "source": [
        "## NonCOVID part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3dpjxLMRjhu"
      },
      "source": [
        "# load pretrained model\r\n",
        "G = Generator(z_dim)\r\n",
        "G.load_state_dict(torch.load('/content/NonCovid__g.pth'))\r\n",
        "G.eval()\r\n",
        "G.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAlPBhSBRpCI"
      },
      "source": [
        "# generate images and save the result\r\n",
        "txtFile = open(\"/content/Data/data/NonCOVID/trainCT_NonCOVID.txt\",\"a+\")\r\n",
        "txtFile.writelines(' \\n')\r\n",
        "for epoch in range(2000):\r\n",
        "  n_output = 1\r\n",
        "  z_sample = Variable(torch.randn(n_output, z_dim)).cuda()\r\n",
        "  imgs_sample = (G(z_sample).data + 1) / 2.0\r\n",
        "  save_dir = '/content/Images/image/CT_NonCOVID'\r\n",
        "  filename = os.path.join(save_dir, f'NonCovid_{epoch+1:03d}.jpg')\r\n",
        "  txtFile.write(f'NonCovid_{epoch+1:03d}.jpg\\n')\r\n",
        "  torchvision.utils.save_image(imgs_sample, filename, nrow=1)\r\n",
        "txtFile.close()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsCAp2yFPVZr"
      },
      "source": [
        "# training with ViT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5UivlYQ-yNd"
      },
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\r\n",
        "train_transformer = transforms.Compose([\r\n",
        "    transforms.Resize(224),\r\n",
        "    transforms.RandomResizedCrop((224),scale=(0.5,1.0)),\r\n",
        "    transforms.RandomHorizontalFlip(),\r\n",
        "    # random brightness and random contrast\r\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\r\n",
        "    transforms.ToTensor(),\r\n",
        "    normalize\r\n",
        "])\r\n",
        "\r\n",
        "val_transformer = transforms.Compose([\r\n",
        "    transforms.Resize((224,224)),\r\n",
        "    transforms.ToTensor(),\r\n",
        "    normalize\r\n",
        "])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E0DD-9z_n8X"
      },
      "source": [
        "batchsize = 16\r\n",
        "def read_txt(txt_path):\r\n",
        "    with open(txt_path) as f:\r\n",
        "        lines = f.readlines()\r\n",
        "    txt_data = [line.strip() for line in lines]\r\n",
        "    return txt_data\r\n",
        "\r\n",
        "class CovidCTDataset(Dataset):\r\n",
        "    def __init__(self, root_dir, txt_COVID, txt_NonCOVID, transform=None):\r\n",
        "        \"\"\"\r\n",
        "        Args:\r\n",
        "            txt_path (string): Path to the txt file with annotations.\r\n",
        "            root_dir (string): Directory with all the images.\r\n",
        "            transform (callable, optional): Optional transform to be applied\r\n",
        "                on a sample.\r\n",
        "        File structure:\r\n",
        "        - root_dir\r\n",
        "            - CT_COVID\r\n",
        "                - img1.png\r\n",
        "                - img2.png\r\n",
        "                - ......\r\n",
        "            - CT_NonCOVID\r\n",
        "                - img1.png\r\n",
        "                - img2.png\r\n",
        "                - ......\r\n",
        "        \"\"\"\r\n",
        "        self.root_dir = root_dir\r\n",
        "        self.txt_path = [txt_COVID,txt_NonCOVID]\r\n",
        "        self.classes = ['CT_COVID', 'CT_NonCOVID']\r\n",
        "        self.num_cls = len(self.classes)\r\n",
        "        self.img_list = []\r\n",
        "        for c in range(self.num_cls):\r\n",
        "            cls_list = [[os.path.join(self.root_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]\r\n",
        "            self.img_list += cls_list\r\n",
        "        self.transform = transform\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.img_list)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        if torch.is_tensor(idx):\r\n",
        "            idx = idx.tolist()\r\n",
        "\r\n",
        "        img_path = self.img_list[idx][0]\r\n",
        "        image = Image.open(img_path).convert('RGB')\r\n",
        "\r\n",
        "        if self.transform:\r\n",
        "            image = self.transform(image)\r\n",
        "        sample = {'img': image,\r\n",
        "                  'label': int(self.img_list[idx][1])}\r\n",
        "        return sample\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "if __name__ == '__main__':\r\n",
        "    trainset = CovidCTDataset(root_dir='/content/Images/image',\r\n",
        "                              txt_COVID='/content/Data/data/COVID/trainCT_COVID.txt',\r\n",
        "                              txt_NonCOVID='/content/Data/data/NonCOVID/trainCT_NonCOVID.txt',\r\n",
        "                              transform= train_transformer)\r\n",
        "    valset = CovidCTDataset(root_dir='/content/Images/image',\r\n",
        "                              txt_COVID='/content/Data/data/COVID/valCT_COVID.txt',\r\n",
        "                              txt_NonCOVID='/content/Data/data/NonCOVID/valCT_NonCOVID.txt',\r\n",
        "                              transform= val_transformer)\r\n",
        "    testset = CovidCTDataset(root_dir='/content/Images/image',\r\n",
        "                              txt_COVID='/content/Data/data/COVID/testCT_COVID.txt',\r\n",
        "                              txt_NonCOVID='/content/Data/data/NonCOVID/testCT_NonCOVID.txt',\r\n",
        "                              transform= val_transformer)\r\n",
        "    print(trainset.__len__())\r\n",
        "    print(valset.__len__())\r\n",
        "    print(testset.__len__())\r\n",
        "\r\n",
        "    train_loader = DataLoader(trainset, batch_size=batchsize, drop_last=False, shuffle=True)\r\n",
        "    val_loader = DataLoader(valset, batch_size=batchsize, drop_last=False, shuffle=False)\r\n",
        "    test_loader = DataLoader(testset, batch_size=batchsize, drop_last=False, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VZacb8kFmoI"
      },
      "source": [
        "for batch_index, batch_samples in enumerate(train_loader):      \r\n",
        "  data, target = batch_samples['img'], batch_samples['label']\r\n",
        "skimage.io.imshow(data[0,1,:,:].numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6Ol2SfwHkVg"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcoKV-0QNKuC"
      },
      "source": [
        "device = 'cuda'\r\n",
        "def train(optimizer, epoch):\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    train_loss = 0\r\n",
        "    train_correct = 0\r\n",
        "    \r\n",
        "    for batch_index, batch_samples in enumerate(train_loader):\r\n",
        "        \r\n",
        "        # move data to device\r\n",
        "        data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\r\n",
        "        \r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        output = model(data)\r\n",
        "        criteria = nn.CrossEntropyLoss()\r\n",
        "        loss = criteria(output, target.long())\r\n",
        "        \r\n",
        "\r\n",
        "        train_loss += criteria(output, target.long())\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        pred = output.argmax(dim=1, keepdim=True)\r\n",
        "        train_correct += pred.eq(target.long().view_as(pred)).sum().item()\r\n",
        "    \r\n",
        "        # Display progress and write to tensorboard\r\n",
        "        if batch_index % bs == 0:\r\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(\r\n",
        "                epoch, batch_index, len(train_loader),\r\n",
        "                100.0 * batch_index / len(train_loader), loss.item()/ bs))\r\n",
        "    "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDlXYl2gOocN"
      },
      "source": [
        "#val process is defined here\r\n",
        "\r\n",
        "def val(epoch):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    test_loss = 0\r\n",
        "    correct = 0\r\n",
        "    results = []\r\n",
        "    \r\n",
        "    TP = 0\r\n",
        "    TN = 0\r\n",
        "    FN = 0\r\n",
        "    FP = 0\r\n",
        "    \r\n",
        "    \r\n",
        "    criteria = nn.CrossEntropyLoss()\r\n",
        "    # Don't update model\r\n",
        "    with torch.no_grad():\r\n",
        "        tpr_list = []\r\n",
        "        fpr_list = []\r\n",
        "        \r\n",
        "        predlist=[]\r\n",
        "        scorelist=[]\r\n",
        "        targetlist=[]\r\n",
        "        # Predict\r\n",
        "        for batch_index, batch_samples in enumerate(val_loader):\r\n",
        "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\r\n",
        "            \r\n",
        "            output = model(data)\r\n",
        "            \r\n",
        "            test_loss += criteria(output, target.long())\r\n",
        "            score = F.softmax(output, dim=1)\r\n",
        "            pred = output.argmax(dim=1, keepdim=True)\r\n",
        "            correct += pred.eq(target.long().view_as(pred)).sum().item()\r\n",
        "            \r\n",
        "            targetcpu=target.long().cpu().numpy()\r\n",
        "            predlist=np.append(predlist, pred.cpu().numpy())\r\n",
        "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\r\n",
        "            targetlist=np.append(targetlist,targetcpu)\r\n",
        "           \r\n",
        "    return targetlist, scorelist, predlist\r\n",
        "    "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORpJmMJzOqOv"
      },
      "source": [
        "#test process is defined here \r\n",
        "\r\n",
        "def test(epoch):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    test_loss = 0\r\n",
        "    correct = 0\r\n",
        "    results = []\r\n",
        "    \r\n",
        "    TP = 0\r\n",
        "    TN = 0\r\n",
        "    FN = 0\r\n",
        "    FP = 0\r\n",
        "    \r\n",
        "    \r\n",
        "    criteria = nn.CrossEntropyLoss()\r\n",
        "    # Don't update model\r\n",
        "    with torch.no_grad():\r\n",
        "        tpr_list = []\r\n",
        "        fpr_list = []\r\n",
        "        \r\n",
        "        predlist=[]\r\n",
        "        scorelist=[]\r\n",
        "        targetlist=[]\r\n",
        "        # Predict\r\n",
        "        for batch_index, batch_samples in enumerate(test_loader):\r\n",
        "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\r\n",
        "            output = model(data)\r\n",
        "            \r\n",
        "            test_loss += criteria(output, target.long())\r\n",
        "            score = F.softmax(output, dim=1)\r\n",
        "            pred = output.argmax(dim=1, keepdim=True)\r\n",
        "            correct += pred.eq(target.long().view_as(pred)).sum().item()\r\n",
        "\r\n",
        "            targetcpu=target.long().cpu().numpy()\r\n",
        "            predlist=np.append(predlist, pred.cpu().numpy())\r\n",
        "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\r\n",
        "            targetlist=np.append(targetlist,targetcpu)\r\n",
        "    return targetlist, scorelist, predlist\r\n",
        "    "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg4yb7GzO1FN"
      },
      "source": [
        "# train\r\n",
        "bs = 4\r\n",
        "votenum = 10\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "model.to(device)\r\n",
        "r_list = []\r\n",
        "p_list = []\r\n",
        "acc_list = []\r\n",
        "AUC_list = []\r\n",
        "# TP = 0\r\n",
        "# TN = 0\r\n",
        "# FN = 0\r\n",
        "# FP = 0\r\n",
        "vote_pred = np.zeros(valset.__len__())\r\n",
        "vote_score = np.zeros(valset.__len__())\r\n",
        "\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\r\n",
        "                                             \r\n",
        "scheduler = StepLR(optimizer, step_size=1)\r\n",
        "\r\n",
        "total_epoch = 30\r\n",
        "for epoch in range(1, total_epoch+1):\r\n",
        "    train(optimizer, epoch)\r\n",
        "    \r\n",
        "    targetlist, scorelist, predlist = val(epoch)\r\n",
        "    print('target',targetlist)\r\n",
        "    print('score',scorelist)\r\n",
        "    print('predict',predlist)\r\n",
        "    vote_pred = vote_pred + predlist \r\n",
        "    vote_score = vote_score + scorelist \r\n",
        "\r\n",
        "    if epoch % votenum == 0:\r\n",
        "        \r\n",
        "        # major vote\r\n",
        "        vote_pred[vote_pred <= (votenum/2)] = 0\r\n",
        "        vote_pred[vote_pred > (votenum/2)] = 1\r\n",
        "        vote_score = vote_score/votenum\r\n",
        "        \r\n",
        "        print('vote_pred', vote_pred)\r\n",
        "        print('targetlist', targetlist)\r\n",
        "        TP = ((vote_pred == 1) & (targetlist == 1)).sum()\r\n",
        "        TN = ((vote_pred == 0) & (targetlist == 0)).sum()\r\n",
        "        FN = ((vote_pred == 0) & (targetlist == 1)).sum()\r\n",
        "        FP = ((vote_pred == 1) & (targetlist == 0)).sum()\r\n",
        "        \r\n",
        "        \r\n",
        "        print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\r\n",
        "        print('TP+FP',TP+FP)\r\n",
        "        p = TP / (TP + FP)\r\n",
        "        print('precision',p)\r\n",
        "        p = TP / (TP + FP)\r\n",
        "        r = TP / (TP + FN)\r\n",
        "        print('recall',r)\r\n",
        "        F1 = 2 * r * p / (r + p)\r\n",
        "        acc = (TP + TN) / (TP + TN + FP + FN)\r\n",
        "        print('F1',F1)\r\n",
        "        print('acc',acc)\r\n",
        "        AUC = roc_auc_score(targetlist, vote_score)\r\n",
        "        print('AUCp', roc_auc_score(targetlist, vote_pred))\r\n",
        "        print('AUC', AUC)\r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "        vote_pred = np.zeros(valset.__len__())\r\n",
        "        vote_score = np.zeros(valset.__len__())\r\n",
        "        print('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},\\\r\n",
        "average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\r\n",
        "        epoch, r, p, F1, acc, AUC))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyZrwVC1GWPD"
      },
      "source": [
        "# torch.save(model, 'model.pth')\r\n",
        "torch.save(model.state_dict(), \"./model.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGOkL_tStkF7"
      },
      "source": [
        "# test part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD5YFIhTPOrL"
      },
      "source": [
        "# test\r\n",
        "bs = 10\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "epoch = 1\r\n",
        "r_list = []\r\n",
        "p_list = []\r\n",
        "acc_list = []\r\n",
        "AUC_list = []\r\n",
        "# TP = 0\r\n",
        "# TN = 0\r\n",
        "# FN = 0\r\n",
        "# FP = 0\r\n",
        "vote_pred = np.zeros(testset.__len__())\r\n",
        "vote_score = np.zeros(testset.__len__())\r\n",
        "\r\n",
        "\r\n",
        "targetlist, scorelist, predlist = test(epoch)\r\n",
        "print('target',targetlist)\r\n",
        "print('score',scorelist)\r\n",
        "print('predict',predlist)\r\n",
        "vote_pred = vote_pred + predlist \r\n",
        "vote_score = vote_score + scorelist \r\n",
        "\r\n",
        "TP = ((predlist == 1) & (targetlist == 1)).sum()\r\n",
        "\r\n",
        "TN = ((predlist == 0) & (targetlist == 0)).sum()\r\n",
        "FN = ((predlist == 0) & (targetlist == 1)).sum()\r\n",
        "FP = ((predlist == 1) & (targetlist == 0)).sum()\r\n",
        "\r\n",
        "print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\r\n",
        "print('TP+FP',TP+FP)\r\n",
        "p = TP / (TP + FP)\r\n",
        "print('precision',p)\r\n",
        "p = TP / (TP + FP)\r\n",
        "r = TP / (TP + FN)\r\n",
        "print('recall',r)\r\n",
        "F1 = 2 * r * p / (r + p)\r\n",
        "acc = (TP + TN) / (TP + TN + FP + FN)\r\n",
        "print('F1',F1)\r\n",
        "print('acc',acc)\r\n",
        "AUC = roc_auc_score(targetlist, vote_score)\r\n",
        "print('AUC', AUC)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}