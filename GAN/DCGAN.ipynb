{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDI23IU5rIBQ"
      },
      "source": [
        "workspace_dir = '.'\r\n",
        "!gdown --id '1E7sVpfnil2Oc6iWl_1iG-dHu2wf6m9K4' --output \"{workspace_dir}/image.zip\"\r\n",
        "!gdown --id '15T9x8yvQSdZveNqypH-4aYu_WJ2fsXes' --output \"{workspace_dir}/data.zip\"\r\n",
        "!unzip -q \"{workspace_dir}/image.zip\" -d \"{workspace_dir}/\"\r\n",
        "!unzip -q \"{workspace_dir}/data.zip\" -d \"{workspace_dir}/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7VUABb0ragG"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "class ImgDataset(Dataset):\r\n",
        "    def __init__(self, fnames, transform):\r\n",
        "        self.transform = transform\r\n",
        "        self.fnames = fnames\r\n",
        "        self.num_samples = len(self.fnames)\r\n",
        "    def __len__(self):\r\n",
        "        return self.num_samples\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        fname = self.fnames[idx]\r\n",
        "        img = cv2.imread(fname, 0)\r\n",
        "        img = self.transform(img)\r\n",
        "        return img\r\n",
        "\r\n",
        "import glob\r\n",
        "import torchvision.transforms as transforms\r\n",
        "\r\n",
        "def get_dataset(root):\r\n",
        "    fnames = glob.glob(os.path.join(root, '*'))\r\n",
        "    # resize the image to (64, 64)\r\n",
        "    # linearly map [0, 1] to [-1, 1]\r\n",
        "    transform = transforms.Compose(\r\n",
        "         [transforms.ToPILImage(),\r\n",
        "         transforms.Resize((64, 64)),\r\n",
        "         transforms.CenterCrop(64),\r\n",
        "         transforms.ToTensor(),\r\n",
        "         transforms.Normalize(mean=[0.5], std=[0.5]) ] )\r\n",
        "    dataset = ImgDataset(fnames, transform)\r\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H99By2FGre5k"
      },
      "source": [
        "import random\r\n",
        "import torch\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def same_seeds(seed):\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        torch.cuda.manual_seed(seed)\r\n",
        "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\r\n",
        "    np.random.seed(seed)  # Numpy module.\r\n",
        "    random.seed(seed)  # Python random module.\r\n",
        "    torch.backends.cudnn.benchmark = False\r\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uflu_UWYrgtz"
      },
      "source": [
        "# custom weights initialization called on netG and netD\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "def weights_init(m):\r\n",
        "    classname = m.__class__.__name__\r\n",
        "    if classname.find('Conv') != -1:\r\n",
        "        m.weight.data.normal_(0.0, 0.02)\r\n",
        "    elif classname.find('BatchNorm') != -1:\r\n",
        "        m.weight.data.normal_(1.0, 0.02)\r\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK7qmCZVrieV"
      },
      "source": [
        "# Generator Code\r\n",
        "\r\n",
        "class Generator(nn.Module):\r\n",
        "    \"\"\"\r\n",
        "    input (N, in_dim)\r\n",
        "    output (N, 1, 64, 64)\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, in_dim, dim=64):\r\n",
        "        super(Generator, self).__init__()\r\n",
        "        def dconv_bn_relu(in_dim, out_dim):\r\n",
        "            return nn.Sequential(\r\n",
        "                nn.ConvTranspose2d(in_dim, out_dim, 5, 2,\r\n",
        "                                   padding=2, output_padding=1, bias=False),\r\n",
        "                nn.BatchNorm2d(out_dim),\r\n",
        "                nn.ReLU())\r\n",
        "        self.l1 = nn.Sequential(\r\n",
        "            nn.Linear(in_dim, dim * 8 * 4 * 4, bias=False),\r\n",
        "            nn.BatchNorm1d(dim * 8 * 4 * 4),\r\n",
        "            nn.ReLU())\r\n",
        "        self.l2_5 = nn.Sequential(\r\n",
        "            dconv_bn_relu(dim * 8, dim * 4),\r\n",
        "            dconv_bn_relu(dim * 4, dim * 2),\r\n",
        "            dconv_bn_relu(dim * 2, dim),\r\n",
        "            nn.ConvTranspose2d(dim, 1, 5, 2, padding=2, output_padding=1),\r\n",
        "            nn.Tanh())\r\n",
        "        self.apply(weights_init)\r\n",
        "    def forward(self, x):\r\n",
        "        y = self.l1(x)\r\n",
        "        y = y.view(y.size(0), -1, 4, 4)\r\n",
        "        y = self.l2_5(y)\r\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgYa271Nrj_1"
      },
      "source": [
        "class Discriminator(nn.Module):\r\n",
        "    \"\"\"\r\n",
        "    input (N, 1, 64, 64)\r\n",
        "    output (N, )\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, in_dim, dim=64):\r\n",
        "        super(Discriminator, self).__init__()\r\n",
        "        def conv_bn_lrelu(in_dim, out_dim):\r\n",
        "            return nn.Sequential(\r\n",
        "                nn.Conv2d(in_dim, out_dim, 5, 2, 2),\r\n",
        "                nn.BatchNorm2d(out_dim),\r\n",
        "                nn.LeakyReLU(0.2))\r\n",
        "        self.ls = nn.Sequential(\r\n",
        "            nn.Conv2d(in_dim, dim, 5, 2, 2), nn.LeakyReLU(0.2),\r\n",
        "            conv_bn_lrelu(dim, dim * 2),\r\n",
        "            conv_bn_lrelu(dim * 2, dim * 4),\r\n",
        "            conv_bn_lrelu(dim * 4, dim * 8),\r\n",
        "            nn.Conv2d(dim * 8, 1, 4),\r\n",
        "            nn.Sigmoid())\r\n",
        "        self.apply(weights_init)        \r\n",
        "    def forward(self, x):\r\n",
        "        y = self.ls(x)\r\n",
        "        y = y.view(-1)\r\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA_xuC-C0lf1"
      },
      "source": [
        "# Convid part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5Sw9uhprmrs"
      },
      "source": [
        "import torch\r\n",
        "from torch import optim\r\n",
        "from torch.autograd import Variable\r\n",
        "import torchvision\r\n",
        "\r\n",
        "# hyperparameters \r\n",
        "batch_size = 32\r\n",
        "z_dim = 100\r\n",
        "lr = 0.002\r\n",
        "lr_d = 0.0002\r\n",
        "n_epoch = 200\r\n",
        "save_dir = os.path.join(workspace_dir, 'Covid')\r\n",
        "os.makedirs(save_dir, exist_ok=True)\r\n",
        "\r\n",
        "# model\r\n",
        "G = Generator(in_dim=z_dim).cuda()\r\n",
        "D = Discriminator(1).cuda()\r\n",
        "G.train()\r\n",
        "D.train()\r\n",
        "\r\n",
        "# loss criterion\r\n",
        "criterion = nn.BCELoss()\r\n",
        "\r\n",
        "# optimizer\r\n",
        "opt_D = torch.optim.Adam(D.parameters(), lr=lr_d, betas=(0.5, 0.999))\r\n",
        "opt_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\r\n",
        "\r\n",
        "\r\n",
        "same_seeds(0)\r\n",
        "# dataloader (You might need to edit the dataset path if you use extra dataset.)\r\n",
        "Covid_dataset = get_dataset(os.path.join(workspace_dir, '/content/Images/image/CT_COVID'))\r\n",
        "Covid_dataloader = DataLoader(Covid_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldjD4Gq6ryUC"
      },
      "source": [
        "# Plot some training images\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torchvision.utils as vutils\r\n",
        "# Decide which device we want to run on\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "real_batch = next(iter(Covid_dataloader))\r\n",
        "plt.figure(figsize=(1,1))\r\n",
        "plt.axis(\"off\")\r\n",
        "plt.title(\"Training Covid Images\")\r\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogAguLoDsEZk"
      },
      "source": [
        "# for logging\r\n",
        "z_sample = Variable(torch.randn(100, z_dim)).cuda()\r\n",
        "\r\n",
        "for e, epoch in enumerate(range(n_epoch)):\r\n",
        "    for i, data in enumerate(Covid_dataloader):\r\n",
        "        imgs = data\r\n",
        "        imgs = imgs.cuda()\r\n",
        "\r\n",
        "        bs = imgs.size(0)\r\n",
        "\r\n",
        "        \"\"\" Train D \"\"\"\r\n",
        "        z = Variable(torch.randn(bs, z_dim)).cuda()\r\n",
        "        r_imgs = Variable(imgs).cuda()\r\n",
        "        f_imgs = G(z)\r\n",
        "\r\n",
        "        # label        \r\n",
        "        f_label = torch.zeros((bs)).cuda()\r\n",
        "        r_label = torch.ones((bs)).cuda()\r\n",
        "\r\n",
        "        # dis\r\n",
        "        r_logit = D(r_imgs.detach())\r\n",
        "        f_logit = D(f_imgs.detach())\r\n",
        "        \r\n",
        "        # compute loss\r\n",
        "        r_loss = criterion(r_logit, r_label)\r\n",
        "        f_loss = criterion(f_logit, f_label)\r\n",
        "        loss_D = (r_loss + f_loss) / 2\r\n",
        "\r\n",
        "        # update model\r\n",
        "        D.zero_grad()\r\n",
        "        loss_D.backward()\r\n",
        "        opt_D.step()\r\n",
        "\r\n",
        "        \"\"\" train G \"\"\"\r\n",
        "        # leaf\r\n",
        "        z = Variable(torch.randn(bs, z_dim)).cuda()\r\n",
        "        f_imgs = G(z)\r\n",
        "\r\n",
        "        # dis\r\n",
        "        f_logit = D(f_imgs)\r\n",
        "        \r\n",
        "        # compute loss\r\n",
        "        loss_G = criterion(f_logit, r_label)\r\n",
        "\r\n",
        "        # update model\r\n",
        "        G.zero_grad()\r\n",
        "        loss_G.backward()\r\n",
        "        opt_G.step()\r\n",
        "\r\n",
        "        # log\r\n",
        "        print(f'\\rEpoch [{epoch+1}/{n_epoch}] {i+1}/{len(Covid_dataloader)} Loss_D: {loss_D.item():.4f} Loss_G: {loss_G.item():.4f}', end='')\r\n",
        "    G.eval()\r\n",
        "    f_imgs_sample = (G(z_sample).data + 1) / 2.0\r\n",
        "    filename = os.path.join(save_dir, f'Epoch_{epoch+1:03d}.jpg')\r\n",
        "    torchvision.utils.save_image(f_imgs_sample, filename, nrow=10)\r\n",
        "    print(f' | Save some samples to {filename}.')\r\n",
        "    # show generated image\r\n",
        "    grid_img = torchvision.utils.make_grid(f_imgs_sample.cpu(), nrow=10)\r\n",
        "    plt.figure(figsize=(10,10))\r\n",
        "    plt.imshow(grid_img.permute(1, 2, 0))\r\n",
        "    plt.show()\r\n",
        "    G.train()\r\n",
        "    if (e+1) % 5 == 0:\r\n",
        "        torch.save(G.state_dict(), os.path.join(workspace_dir, f'Covid__g.pth'))\r\n",
        "        torch.save(D.state_dict(), os.path.join(workspace_dir, f'Covid__d.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZXfyr2EsZ60"
      },
      "source": [
        "# load pretrained model\r\n",
        "G = Generator(z_dim)\r\n",
        "G.load_state_dict(torch.load(os.path.join(workspace_dir, 'Covid__g.pth')))\r\n",
        "G.eval()\r\n",
        "G.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acex0CgDsiai"
      },
      "source": [
        "# generate images and save the result\r\n",
        "for epoch in range(1000):\r\n",
        "  n_output = 1\r\n",
        "  z_sample = Variable(torch.randn(n_output, z_dim)).cuda()\r\n",
        "  imgs_sample = (G(z_sample).data + 1) / 2.0\r\n",
        "  save_dir = os.path.join(workspace_dir, 'Covid')\r\n",
        "  filename = os.path.join(save_dir, f'Covid_{epoch+1:03d}.jpg')\r\n",
        "  torchvision.utils.save_image(imgs_sample, filename, nrow=1)\r\n",
        "  # show image\r\n",
        "  grid_img = torchvision.utils.make_grid(imgs_sample.cpu(), nrow=1)\r\n",
        "  plt.figure(figsize=(1,1))\r\n",
        "  plt.imshow(grid_img.permute(1, 2, 0))\r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMr60ydJ0rVq"
      },
      "source": [
        "# NonCovid part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baM3JGQXxFYI"
      },
      "source": [
        "# NonCovid dataset\r\n",
        "import torch\r\n",
        "from torch import optim\r\n",
        "from torch.autograd import Variable\r\n",
        "import torchvision\r\n",
        "\r\n",
        "# hyperparameters \r\n",
        "batch_size = 32\r\n",
        "z_dim = 100\r\n",
        "lr = 0.002\r\n",
        "lr_d = 0.0002\r\n",
        "n_epoch = 200\r\n",
        "save_dir = os.path.join(workspace_dir, 'NonCovid')\r\n",
        "os.makedirs(save_dir, exist_ok=True)\r\n",
        "\r\n",
        "# model\r\n",
        "G = Generator(in_dim=z_dim).cuda()\r\n",
        "D = Discriminator(1).cuda()\r\n",
        "G.train()\r\n",
        "D.train()\r\n",
        "\r\n",
        "# loss criterion\r\n",
        "criterion = nn.BCELoss()\r\n",
        "\r\n",
        "# optimizer\r\n",
        "opt_D = torch.optim.Adam(D.parameters(), lr=lr_d, betas=(0.5, 0.999))\r\n",
        "opt_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\r\n",
        "\r\n",
        "\r\n",
        "same_seeds(0)\r\n",
        "# dataloader (You might need to edit the dataset path if you use extra dataset.)\r\n",
        "NonCovid_dataset = get_dataset(os.path.join(workspace_dir, '/content/Images/image/CT_NonCOVID'))\r\n",
        "NonCovid_dataloader = DataLoader(NonCovid_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbHU9oAlxfn0"
      },
      "source": [
        "# Plot some training images\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torchvision.utils as vutils\r\n",
        "# Decide which device we want to run on\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "real_batch = next(iter(NonCovid_dataloader))\r\n",
        "plt.figure(figsize=(1,1))\r\n",
        "plt.axis(\"off\")\r\n",
        "plt.title(\"Training NonCovid Images\")\r\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u60iiZk4xuoG"
      },
      "source": [
        "# for logging\r\n",
        "z_sample = Variable(torch.randn(100, z_dim)).cuda()\r\n",
        "\r\n",
        "for e, epoch in enumerate(range(n_epoch)):\r\n",
        "    for i, data in enumerate(NonCovid_dataloader):\r\n",
        "        imgs = data\r\n",
        "        imgs = imgs.cuda()\r\n",
        "\r\n",
        "        bs = imgs.size(0)\r\n",
        "\r\n",
        "        \"\"\" Train D \"\"\"\r\n",
        "        z = Variable(torch.randn(bs, z_dim)).cuda()\r\n",
        "        r_imgs = Variable(imgs).cuda()\r\n",
        "        f_imgs = G(z)\r\n",
        "\r\n",
        "        # label        \r\n",
        "        r_label = torch.ones((bs)).cuda()\r\n",
        "        f_label = torch.zeros((bs)).cuda()\r\n",
        "\r\n",
        "        # dis\r\n",
        "        r_logit = D(r_imgs.detach())\r\n",
        "        f_logit = D(f_imgs.detach())\r\n",
        "        \r\n",
        "        # compute loss\r\n",
        "        r_loss = criterion(r_logit, r_label)\r\n",
        "        f_loss = criterion(f_logit, f_label)\r\n",
        "        loss_D = (r_loss + f_loss) / 2\r\n",
        "\r\n",
        "        # update model\r\n",
        "        D.zero_grad()\r\n",
        "        loss_D.backward()\r\n",
        "        opt_D.step()\r\n",
        "\r\n",
        "        \"\"\" train G \"\"\"\r\n",
        "        # leaf\r\n",
        "        z = Variable(torch.randn(bs, z_dim)).cuda()\r\n",
        "        f_imgs = G(z)\r\n",
        "\r\n",
        "        # dis\r\n",
        "        f_logit = D(f_imgs)\r\n",
        "        \r\n",
        "        # compute loss\r\n",
        "        loss_G = criterion(f_logit, r_label)\r\n",
        "\r\n",
        "        # update model\r\n",
        "        G.zero_grad()\r\n",
        "        loss_G.backward()\r\n",
        "        opt_G.step()\r\n",
        "\r\n",
        "        # log\r\n",
        "        print(f'\\rEpoch [{epoch+1}/{n_epoch}] {i+1}/{len(NonCovid_dataloader)} Loss_D: {loss_D.item():.4f} Loss_G: {loss_G.item():.4f}', end='')\r\n",
        "    G.eval()\r\n",
        "    f_imgs_sample = (G(z_sample).data + 1) / 2.0\r\n",
        "    filename = os.path.join(save_dir, f'Epoch_{epoch+1:03d}.jpg')\r\n",
        "    torchvision.utils.save_image(f_imgs_sample, filename, nrow=10)\r\n",
        "    print(f' | Save some samples to {filename}.')\r\n",
        "    # show generated image\r\n",
        "    grid_img = torchvision.utils.make_grid(f_imgs_sample.cpu(), nrow=10)\r\n",
        "    plt.figure(figsize=(10,10))\r\n",
        "    plt.imshow(grid_img.permute(1, 2, 0))\r\n",
        "    plt.show()\r\n",
        "    G.train()\r\n",
        "    if (e+1) % 5 == 0:\r\n",
        "        torch.save(G.state_dict(), os.path.join(workspace_dir, f'NonCovid__g.pth'))\r\n",
        "        torch.save(D.state_dict(), os.path.join(workspace_dir, f'NonCovid__d.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6EVmZWhyFJp"
      },
      "source": [
        "# load pretrained model\r\n",
        "G = Generator(z_dim)\r\n",
        "G.load_state_dict(torch.load(os.path.join(workspace_dir, 'NonCovid__g.pth')))\r\n",
        "G.eval()\r\n",
        "G.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0ZgyndHyQqq"
      },
      "source": [
        "# generate images and save the result\r\n",
        "for epoch in range(1000):\r\n",
        "  n_output = 1\r\n",
        "  z_sample = Variable(torch.randn(n_output, z_dim)).cuda()\r\n",
        "  imgs_sample = (G(z_sample).data + 1) / 2.0\r\n",
        "  save_dir = os.path.join(workspace_dir, 'NonCovid')\r\n",
        "  filename = os.path.join(save_dir, f'NonCovid_{epoch+1:03d}.jpg')\r\n",
        "  torchvision.utils.save_image(imgs_sample, filename, nrow=1)\r\n",
        "  # show image\r\n",
        "  grid_img = torchvision.utils.make_grid(imgs_sample.cpu(), nrow=1)\r\n",
        "  plt.figure(figsize=(1,1))\r\n",
        "  plt.imshow(grid_img.permute(1, 2, 0))\r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}